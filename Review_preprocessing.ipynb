{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용할 분류 : 꼬꼬마(Kkma) , Okt , Mecab\n",
    "\n",
    "사용할 모델 : LSTM(비교용) ,양방향 LSTM (Bi-LSTM)\n",
    "\n",
    "도입해보고 그 결과 수치가 어느정도 차이 나는지 정도로 작성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bi LSTM 관련 링크\n",
    "\n",
    "이론 : https://wegonnamakeit.tistory.com/25\n",
    "\n",
    "사용 예제 : https://wikidocs.net/94748\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모듈 선언\n",
    "가능하다면 작업 완료 후 전부 여기에 할당할것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "from konlpy.tag import Okt\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 훈련 데이터 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./dataset/ratings_test.txt', <http.client.HTTPMessage at 0x150bfd90520>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"./dataset/ratings_train.txt\")\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"./dataset/ratings_test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터를 변수에 담아주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_table('./dataset/ratings_train.txt')\n",
    "test_data = pd.read_table('./dataset/ratings_test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 중복 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146182, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['document'].nunique(), train_data['label'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 중복 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop_duplicates(subset=['document'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 수 : 146183\n"
     ]
    }
   ],
   "source": [
    "print('총 샘플의 수 :',len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 리뷰 중에 Null 값을 가진 샘플이 있는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(train_data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True가 나왔다면 데이터 중에 Null 값을 가진 샘플이 존재한다는 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id          0\n",
      "document    1\n",
      "label       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Null 값을 가진 샘플을 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n",
    "print(train_data.isnull().values.any()) # Null 값이 존재하는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146182\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정규 표현식 수행\n",
    "\n",
    "온점 같은 구두점들 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp/ipykernel_17488/3198192014.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 솔직히 재미는 없다평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                  아 더빙 진짜 짜증나네요 목소리      0\n",
       "1   3819312                         흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                          교도소 이야기구먼 솔직히 재미는 없다평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 한글과 공백을 제외하고 모두 제거\n",
    "train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "공백만 있거나 빈 값이 있는 데이터 Null 처리 및 존재 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id            0\n",
      "document    789\n",
      "label         0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp/ipykernel_17488/1225369754.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['document'] = train_data['document'].str.replace('^ +', \"\") # white space 데이터를 empty value로 변경\n"
     ]
    }
   ],
   "source": [
    "train_data['document'] = train_data['document'].str.replace('^ +', \"\") # white space 데이터를 empty value로 변경\n",
    "train_data['document'].replace('', np.nan, inplace=True)\n",
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>4221289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>9509970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>10147571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>7117896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>6478189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id document  label\n",
       "404   4221289      NaN      0\n",
       "412   9509970      NaN      1\n",
       "470  10147571      NaN      1\n",
       "584   7117896      NaN      0\n",
       "593   6478189      NaN      0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.loc[train_data.document.isnull()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null값들 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145393\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.dropna(how = 'any')\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후 테스트용 샘플의 개수 : 48852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp/ipykernel_17488/2045415552.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규 표현식 수행\n",
      "C:\\Temp/ipykernel_17488/2045415552.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_data['document'] = test_data['document'].str.replace('^ +', \"\") # 공백은 empty 값으로 변경\n"
     ]
    }
   ],
   "source": [
    "test_data.drop_duplicates(subset = ['document'], inplace=True) # document 열에서 중복인 내용이 있다면 중복 제거\n",
    "test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규 표현식 수행\n",
    "test_data['document'] = test_data['document'].str.replace('^ +', \"\") # 공백은 empty 값으로 변경\n",
    "test_data['document'].replace('', np.nan, inplace=True) # 공백은 Null 값으로 변경\n",
    "test_data = test_data.dropna(how='any') # Null 값 제거\n",
    "print('전처리 후 테스트용 샘플의 개수 :',len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3만 : 1만의 3:1 비율로 샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플링한 훈련 샘플 수 : 30000\n",
      "샘플링한 테스트 샘플 수 : 10000\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.sample(n = 30000, random_state = 1)\n",
    "test_data = test_data.sample(n = 10000, random_state = 1)\n",
    "\n",
    "print('샘플링한 훈련 샘플 수 :',len(train_data))\n",
    "print('샘플링한 테스트 샘플 수 :',len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) 토큰화\n",
    "\n",
    "원문에서는 OKT를 사용했지만\n",
    "\n",
    "추가적으로 꼬꼬마(Kkma),Mecab(은전한닢)을 사용해보도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "형태소 분석 : ['조건', '과', '편리함', '만', '을', '따지', '는', '요즘', '세대', '들', '이', '진정', '하', 'ㄴ', '사랑이', '무엇', '이', 'ㄴ지', '보', '고', '배우', '어야', '하', 'ㄹ', '영화']\n",
      "품사 태깅 : [('조건', 'NNG'), ('과', 'JKM'), ('편리함', 'NNG'), ('만', 'JX'), ('을', 'JKO'), ('따지', 'VV'), ('는', 'ETD'), ('요즘', 'NNG'), ('세대', 'NNG'), ('들', 'XSN'), ('이', 'JKS'), ('진정', 'NNG'), ('하', 'XSV'), ('ㄴ', 'ETD'), ('사랑이', 'NNG'), ('무엇', 'NNG'), ('이', 'VCP'), ('ㄴ지', 'ECD'), ('보', 'VV'), ('고', 'ECE'), ('배우', 'VV'), ('어야', 'ECD'), ('하', 'VV'), ('ㄹ', 'ETD'), ('영화', 'NNG')]\n",
      "명사 추출 : ['조건', '편리함', '요즘', '요즘세대', '세대', '진정', '사랑이', '무엇', '영화']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Kkma\n",
    "#from konlpy.jvm import init_jvm\n",
    "kkma = Kkma()\n",
    "\n",
    "sample_text = train_data.iloc[7, 1]\n",
    "\n",
    "print('형태소 분석 :',kkma.morphs(sample_text))\n",
    "print('품사 태깅 :',kkma.pos(sample_text))\n",
    "print('명사 추출 :',kkma.nouns(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_jvm(jvmpath=None, max_heap_size='8192M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "불용어 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16048/30000 [10:04<08:45, 26.56it/s]  \n"
     ]
    },
    {
     "ename": "java.lang.OutOfMemoryError",
     "evalue": "java.lang.OutOfMemoryError: Java heap space",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\_jpype.cp39-win_amd64.pyd\u001b[0m in \u001b[0;36mkr.lucypark.kkma.KkmaInterface.morphAnalyzer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\_jpype.cp39-win_amd64.pyd\u001b[0m in \u001b[0;36morg.snu.ids.ha.ma.MorphemeAnalyzer.analyze\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\_jpype.cp39-win_amd64.pyd\u001b[0m in \u001b[0;36morg.snu.ids.ha.ma.MorphemeAnalyzer.analyze\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\_jpype.cp39-win_amd64.pyd\u001b[0m in \u001b[0;36mjava.lang.StringBuilder.append\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\_jpype.cp39-win_amd64.pyd\u001b[0m in \u001b[0;36mjava.lang.String.valueOf\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\_jpype.cp39-win_amd64.pyd\u001b[0m in \u001b[0;36morg.snu.ids.ha.ma.MExpression.toString\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\_jpype.cp39-win_amd64.pyd\u001b[0m in \u001b[0;36mjava.lang.StringBuffer.toString\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\_jpype.cp39-win_amd64.pyd\u001b[0m in \u001b[0;36mjava.util.Arrays.copyOfRange\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Java Exception",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mjava.lang.OutOfMemoryError\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Temp/ipykernel_17488/2521231301.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'document'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtokenized_sentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkkma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmorphs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 토큰화\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mstopwords_removed_sentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokenized_sentence\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# 불용어 제거\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstopwords_removed_sentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\konlpy\\tag\\_kkma.py\u001b[0m in \u001b[0;36mmorphs\u001b[1;34m(self, phrase)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;34m\"\"\"Parse phrase to morphemes.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphrase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\konlpy\\tag\\_kkma.py\u001b[0m in \u001b[0;36mpos\u001b[1;34m(self, phrase, flatten, join)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mvalidate_phrase_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjki\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmorphAnalyzer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[0mmorphemes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mjava.lang.OutOfMemoryError\u001b[0m: java.lang.OutOfMemoryError: Java heap space"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "\n",
    "for sentence in tqdm(train_data['document']):\n",
    "    tokenized_sentence = kkma.morphs(sentence) # 토큰화\n",
    "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어 제거\n",
    "    X_train.append(stopwords_removed_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kkma엔 Okt의 stem argument가 없음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['배경', '만', '볼만', '하', 'ㅁ'], ['여기', '전라도', '비하', '하', '인간', '같', '지', '않', '인간', '아', '아', '영화', '내용', '중요', '하', '지', '지역', '중요', '하', '냐', '그러', 'ㅁ', '공주', '에서', '밀양', '이야기', '안', '꺼내', 'ㄴ', '것', '어쩌', 'ㄹ', '것', 'ㄴ데', '아', '아', '자기', '내용', '나오', '아서', '움찔', '하', 'ㄴ', '거', '냐', '함부로', '떠들', 'ㄹ지', '마라'], ['이런', '영화', '좋', '다', '잔잔', '하', 'ㅁ', '속', '공감', '갈', '내용', '작품', '배우', '연기', '좋', '았', '다']]\n"
     ]
    }
   ],
   "source": [
    "# For Check\n",
    "print(X_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트에도 동일하게 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [03:52<00:00, 42.98it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "\n",
    "for sentence in tqdm(test_data['document']):\n",
    "    tokenized_sentence = kkma.morphs(sentence) # 토큰화\n",
    "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어 제거\n",
    "    X_test.append(stopwords_removed_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22.03.19 메모 (1)\n",
    "\n",
    "heap 영역에 메모리 문제 발생\n",
    "\n",
    "+)해결 : init_jvm() 변수로 메모리 할당 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토큰화를 하고 나면 또 하는 작업을 방지하고자 \n",
    "\n",
    "데이터프레임으로 변환하고 csv로 저장하는걸 추천\n",
    "\n",
    "차후 작업에 용이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(X_train).to_csv('./dataset/kkma_x_train.csv',index=False)\n",
    "pd.Series(X_test).to_csv('./dataset/kkma_x_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 14788\n",
      "등장 빈도가 2번 이하인 희귀 단어의 수: 9141\n",
      "단어 집합에서 희귀 단어의 비율: 61.813632675142\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 4.479552797986005\n"
     ]
    }
   ],
   "source": [
    "threshold = 3\n",
    "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "등장 빈도수가 2 이하인 단어들의 수를 제외한 단어의 개수를 집합의 Max로 제한"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 5648\n"
     ]
    }
   ],
   "source": [
    "# 전체 단어 개수 중 빈도수 2이하인 단어는 제거.\n",
    "# 0번 패딩 토큰을 고려하여 + 1\n",
    "vocab_size = total_cnt - rare_cnt + 1\n",
    "print('단어 집합의 크기 :',vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스 토크나이저의 인자로 넘겨주고 텍스트 시퀀스를 정수 시퀀스로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab_size) \n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[591, 26, 428, 1, 21], [467, 2210, 634, 1, 302, 34, 14, 38, 302, 12, 12, 3, 72, 766, 1, 14, 2602, 766, 1, 89, 296, 21, 2397, 35, 138, 44, 2, 15, 559, 10, 15, 73, 12, 12, 581, 72, 50, 90, 1, 2, 49, 89, 3703, 3227, 341, 496], [69, 3, 19, 4, 451, 1, 21, 223, 317, 232, 72, 109, 70, 40, 19, 13, 4]]\n"
     ]
    }
   ],
   "source": [
    "# For Check\n",
    "print(X_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_data에서 y_train과 y_test를 별도로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_data['label'])\n",
    "y_test = np.array(test_data['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 빈 샘플 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_train = [index for index, sentence in enumerate(X_train) if len(sentence) < 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16029\n",
      "29981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JW\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "# 빈 샘플들을 제거\n",
    "X_train = np.delete(X_train, drop_train, axis=0)\n",
    "y_train = np.delete(y_train, drop_train, axis=0)\n",
    "print(len(X_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰의 최대 길이 : 82\n",
      "리뷰의 평균 길이 : 15.031255848774096\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAcAElEQVR4nO3dfZhdZX3u8e9NhPBiEDCRExPCBBupgBJgSLGi5UUhEivQVkjORUGhRmlswLeepFqhenIaj4qKPQaDUEAhyBEQDqAQKYjWCEwgkvBWAgkyJIdEQQggqQm//rGekc1kz6yVyay91sy+P9e1rtn72evlziSZ36xnrfU8igjMzMz6s13VAczMrP5cLMzMLJeLhZmZ5XKxMDOzXC4WZmaW6zVVByjL6NGjo6Ojo+oYZmZDytKlS38dEWN6tw/bYtHR0UFXV1fVMczMhhRJjzdrdzeUmZnlcrEwM7NcLhZmZpbLxcLMzHK5WJiZWS4XCzMzy+ViYWZmuVwszMwsl4uFmZnlGrZPcNdBx5wbm7avnj+txUnMzLaNi0UFXETMbKhxN5SZmeVysTAzs1wuFmZmlsvFwszMcrlYmJlZLhcLMzPL5WJhZma5XCzMzCxXacVC0sWS1kla0dD2PUnL0rJa0rLU3iHpdw2fXdCwzSGSlktaKel8SSors5mZNVfmE9yXAP8CXNbTEBEn97yW9BXg2Yb1H42IyU32swCYCfwCuAmYCvxw8OOamVlfSjuziIg7gKebfZbODk4CFvW3D0ljgV0jYklEBFnhOWGQo5qZWY6qrlm8E3gqIh5paJso6V5JP5H0ztQ2DuhuWKc7tTUlaaakLkld69evH/zUZmZtqqpiMYNXn1WsBSZExEHAJ4ArJO0KNLs+EX3tNCIWRkRnRHSOGTNmUAObmbWzlo86K+k1wF8Ah/S0RcRGYGN6vVTSo8Cbyc4kxjdsPh5Y07q0ZmYG1ZxZvBt4KCL+0L0kaYykEen1PsAk4LGIWAtskHRYus5xKnBdBZnNzNpambfOLgKWAPtK6pZ0RvpoOlte2H4XcJ+kXwLfBz4aET0Xx88Evg2sBB7Fd0KZmbVcad1QETGjj/YPNmm7Gri6j/W7gAMGNZyZmW0VP8FtZma5XCzMzCyXi4WZmeVysTAzs1wuFmZmlsvFwszMcrlYmJlZLhcLMzPL5WJhZma5XCzMzCyXi4WZmeVysTAzs1wuFmZmlsvFwszMcrlYmJlZLhcLMzPL5WJhZma5SpspzwZPx5wb+/xs9fxpLUxiZu3KZxZmZpartGIh6WJJ6yStaGg7V9KTkpal5biGz+ZKWinpYUnHNrQfIml5+ux8SSors5mZNVfmmcUlwNQm7V+NiMlpuQlA0n7AdGD/tM03JY1I6y8AZgKT0tJsn2ZmVqLSikVE3AE8XXD144ErI2JjRKwCVgJTJI0Fdo2IJRERwGXACaUENjOzPlVxzeJjku5L3VS7p7ZxwBMN63SntnHpde/2piTNlNQlqWv9+vWDndvMrG21ulgsAN4ETAbWAl9J7c2uQ0Q/7U1FxMKI6IyIzjFjxmxjVDMz69HSYhERT0XE5oh4GbgQmJI+6gb2alh1PLAmtY9v0m5mZi3U0mKRrkH0OBHouVPqemC6pJGSJpJdyL4rItYCGyQdlu6COhW4rpWZzcysxIfyJC0CjgBGS+oGzgGOkDSZrCtpNfARgIi4X9JVwAPAJmBWRGxOuzqT7M6qnYAfpsXMzFqotGIRETOaNF/Uz/rzgHlN2ruAAwYxmpmZbSU/wW1mZrlcLMzMLJeLhZmZ5XKxMDOzXC4WZmaWK7dYSPqApFHp9WclXSPp4PKjmZlZXRQ5s/jHiNgg6XDgWOBSsmE7zMysTRQpFj0Px00DFkTEdcAO5UUyM7O6KVIsnpT0LeAk4CZJIwtuZ2Zmw0SRH/onATcDUyPit8AewKfLDGVmZvWSWywi4kVgHXB4atoEPFJmKDMzq5cid0OdA/wPYG5q2h74bpmhzMysXop0Q50IvB94ASAi1gCjygxlZmb1UqRY/Gea/zoAJO1SbiQzM6ubIsXiqnQ31G6SPgz8mGyWOzMzaxO581lExJclvQd4DtgX+FxELC49mZmZ1UahyY9ScWj7AtEx58am7avnT2txEjOz1uqzWEjaQLpO0fsjICJi19JSmZlZrfR5zSIiRkXErk2WUUUKhaSLJa2TtKKh7UuSHpJ0n6RrJe2W2jsk/U7SsrRc0LDNIZKWS1op6XxJ2sY/s5mZbaVCw3ZIOljSbEl/J+mggvu+BJjaq20xcEBEvA34D155dgPg0YiYnJaPNrQvAGYCk9LSe59mZlayIg/lfY5spNnXA6OBSyR9Nm+7iLgDeLpX2y0RsSm9/QUwPufYY4FdI2JJun33MuCEvGObmdngKnKBewZwUES8BCBpPnAP8D+38dinA99reD9R0r1kd119NiJ+CowDuhvW6U5tZmbWQkWKxWpgR+Cl9H4k8Oi2HFTSZ8jGmLo8Na0FJkTEbyQdAvxA0v5kF9N7a3bRvWe/M8m6rJgwYcK2RDQzswZFisVG4H5Ji8l+UL8H+Jmk8wEiYvbWHFDSacD7gKNT1xIRsTEdh4hYKulR4M1kZxKNXVXjgTV97TsiFgILATo7O/ssKmZmtnWKFItr09Lj9oEeTNJUskEJ/yyNZtvTPgZ4OiI2S9qH7EL2YxHxtKQNkg4D7gROBb4x0OObmdnAFHmC+9KB7FjSIuAIYLSkbuAcsrufRgKL0x2wv0h3Pr0L+LykTWQz8300Inoujp9JdmfVTsAP02JmZi2UWywkvQ/4ArB3Wr/QQ3kRMaNJ80V9rHs1cHUfn3UBB+TlNDOz8hTphvoa8BfA8p5rDGZm1l6KFIsngBUuFEOLx7Eys8FUpFj8PXCTpJ+Q7lgCiIjzSktlZma1UqRYzAOeJ3vWYody45iZWR0VKRZ7RMQxpScxM7PaKjKQ4I8luViYmbWxIsViFvCjNIT4c+khuefKDmZmZvVR5KG8Ua0IYmZm9VVoWlVJu5MNwbFjT1sagtzMzNpAkSe4/wY4i2wQv2XAYcAS4KhSk5mZWW0UuWZxFnAo8HhEHAkcBKwvNZWZmdVKkWLxUsPERyMj4iFg33JjmZlZnRS5ZtEtaTfgB2SjxT5DP3NKmJnZ8FPkbqgT08tzJd0GvA74UampzMysVnK7oSS9SdLInrdAB7BzmaHMzKxeilyzuBrYLOmPyOajmAhcUWoqMzOrlSLF4uWI2AScCHwtIj4OjC03lpmZ1UmRYvF7STOA04AbUtv25UUyM7O6KVIsPgS8HZgXEaskTQS+W24sMzOrk9xiEREPRMTsiFiU3q+KiPl520m6WNI6SSsa2vaQtFjSI+nr7g2fzZW0UtLDko5taD9E0vL02fmStPV/TDMz2xZFziwG6hJgaq+2OcCtETEJuDW9R9J+wHRg/7TNNyWNSNssAGaSjU01qck+zcysZKUVizTQ4NO9mo8HLk2vLwVOaGi/MiI2RsQqYCUwRdJYYNeIWJLmAL+sYRszM2uRPouFpO+kr2cN4vH2jIi1AOnrG1L7OOCJhvW6U9u49Lp3e1+ZZ0rqktS1fr2HrzIzGyz9nVkcImlv4HRJu6frDX9YBjlHs+sQ0U97UxGxMCI6I6JzzJgxgxbOzKzd9TfcxwVkw3rsAyzl1T+4I7VvrackjY2ItamLaV1q7wb2alhvPNn4U93pde92MzNroT7PLCLi/Ih4C3BxROwTERMbloEUCoDryZ7XIH29rqF9uqSR6dbcScBdqatqg6TD0l1QpzZsY2ZmLVJkIMEzJR0IvDM13RER9+VtJ2kRcAQwWlI3cA4wH7hK0hnAr4APpGPcL+kq4AFgEzArIjanXZ1JdmfVTsAP02JmZi1UZKa82WS3rl6Tmi6XtDAivtHfdhExo4+Pju5j/XnAvCbtXcABeTnNzKw8Reaz+BvgTyLiBQBJXySbVrXfYmFmZsNHkecsBGxueL+Z5ncpmZnZMFXkzOJfgTslXZven0A2VLmZmbWJIhe4z5N0O3A42RnFhyLi3rKDmZlZfRQ5syAi7gHuKTmLmZnVVKFiYcNHx5wbm7avnj+txUnMbCgpc9RZMzMbJvo9s0jDhN8cEe9uUZ621tdv/WZmVeu3WETEZkkvSnpdRDzbqlBDjX/Im9lwV+SaxUvAckmLgRd6GiNidmmpzMysVooUixvTYmZmbarIcxaXStoJmBARD7cgk5mZ1Uzu3VCS/hxYRja3BZImS7q+5FxmZlYjRW6dPReYAvwWICKWARNLS2RmZrVTpFhsanInVJ9Tm5qZ2fBT5AL3Ckn/HRghaRIwG/h5ubHMzKxOipxZ/B2wP7ARWAQ8B5xdYiYzM6uZIndDvQh8Jk16FBGxofxYZmZWJ0XuhjpU0nLgPrKH834p6ZDyo5mZWV0U6Ya6CPjbiOiIiA5gFtmESAMiaV9JyxqW5ySdLelcSU82tB/XsM1cSSslPSzp2IEe28zMBqbIBe4NEfHTnjcR8TNJA+6KSg/2TYY/DFT4JHAt8CHgqxHx5cb1Je0HTCe7bvJG4MeS3hwRjVO9mplZifosFpIOTi/vkvQtsovbAZwM3D5Ixz8aeDQiHpf6nNb7eODKiNgIrJK0kuy5jyWDlMHMzHL0d2bxlV7vz2l4PVjPWUwnK0I9PibpVKAL+GREPAOMA37RsE53atuCpJnATIAJEyYMUkQzM+uzWETEkWUeWNIOwPuBualpAfAFskL0BbJidTrZvN9bxGu2z4hYCCwE6Ozs9IODZmaDJPeahaTdgFOBjsb1B2GI8vcC90TEU2l/TzUc80LghvS2G9irYbvxwJptPLaZmW2FIhe4byLrBloOvDyIx55BQxeUpLERsTa9PRFYkV5fD1wh6TyyC9yTgLsGMceQ5omXzKwVihSLHSPiE4N5UEk7A+8BPtLQ/L8lTSbrYlrd81lE3C/pKuABYBMwy3dCmZm1VpFi8R1JHybrFtrY0xgRTw/0oOmp8Nf3avvrftafB8wb6PHMzGzbFCkW/wl8CfgMr1xYDmCfskJZffTVzbV6/rQWJzGzKhUpFp8A/igifl12GDMzq6ciw33cD7xYdhAzM6uvImcWm4Flkm7j1dcstvXWWTMzGyKKFIsfpMXMzNpUkfksLm1FEDMzq68iT3CvosnwGhHhu6HMzNpEkW6ozobXOwIfAPYoJ46ZmdVR7t1QEfGbhuXJiPgacFT50czMrC6KdEMd3PB2O7IzjVGlJTIzs9op0g3VOK/FJrJxm04qJY2ZmdVSkbuhSp3XwszM6q9IN9RI4C/Zcj6Lz5cXy8zM6qRIN9R1wLPAUhqe4DYzs/ZRpFiMj4ippScxM7PaKjKQ4M8lvbX0JGZmVltFziwOBz6YnuTeCAiIiHhbqcnMzKw2ihSL95aewszMaq3IrbOPD/ZBJa0GNpANf74pIjol7QF8j+yuq9XASRHxTFp/LnBGWn92RNw82JnMzKxvRa5ZlOXIiJgcET1jT80Bbo2IScCt6T2S9gOmA/sDU4FvShpRRWAzs3ZVZbHo7XigZzj0S4ETGtqvjIiNEbEKWAlMaX08M7P2VVWxCOAWSUslzUxte0bEWoD09Q2pfRzwRMO23anNzMxapMgF7jK8IyLWSHoDsFjSQ/2sqyZtW8yvAZAKz0yACRMmDDhcx5wbB7ytmdlwVEmxiIg16es6SdeSdSs9JWlsRKyVNBZYl1bvBvZq2Hw8sKaP/S4EFgJ0dnY2LSg2OPoqqKvnT2txEjNrhZZ3Q0naRdKontfAMcAK4HrgtLTaaWTDjJDap0saKWkiMAm4q7WpzczaWxVnFnsC10rqOf4VEfEjSXcDV0k6A/gV2Yx8RMT9kq4CHiAbIn1WRGyuILeZWdtqebGIiMeAA5u0/wY4uo9t5gHzSo7W1nydxsz6U6dbZ83MrKZcLMzMLJeLhZmZ5XKxMDOzXC4WZmaWy8XCzMxyuViYmVkuFwszM8vlYmFmZrlcLMzMLJeLhZmZ5XKxMDOzXC4WZmaWy8XCzMxyuViYmVkuFwszM8vlYmFmZrlcLMzMLJeLhZmZ5Wr5HNyS9gIuA/4b8DKwMCK+Lulc4MPA+rTqP0TETWmbucAZwGZgdkTc3Orctm36muN79fxpLU5iZgPR8mIBbAI+GRH3SBoFLJW0OH321Yj4cuPKkvYDpgP7A28EfizpzRGxuaWpzczaWMu7oSJibUTck15vAB4ExvWzyfHAlRGxMSJWASuBKeUnNTOzHpVes5DUARwE3JmaPibpPkkXS9o9tY0DnmjYrJs+ioukmZK6JHWtX7++2SpmZjYAlRULSa8FrgbOjojngAXAm4DJwFrgKz2rNtk8mu0zIhZGRGdEdI4ZM2bwQ5uZtalKioWk7ckKxeURcQ1ARDwVEZsj4mXgQl7pauoG9mrYfDywppV5zczaXRV3Qwm4CHgwIs5raB8bEWvT2xOBFen19cAVks4ju8A9CbirhZGtAr57yqxeqrgb6h3AXwPLJS1Lbf8AzJA0mayLaTXwEYCIuF/SVcADZHdSzfKdUGZmrdXyYhERP6P5dYib+tlmHjCvtFA2aPo6IzCzoc1PcJuZWS4XCzMzy+ViYWZmuaq4wG02YAO5S8p3VpltO59ZmJlZLhcLMzPL5W4oq1SVt9q6e8qsOBcLs4JcXKyduRvKzMxyuViYmVkud0OZtdjWdme5+8vqwMXCbJjp76YBFxgbKBcLs5IMh0EVfVZjPVwszHoZDj/k+zJYP/xdRNqPi4UNC8P5B/xw4OIy9LlYmG0jFyprBy4WZjXhomN15mJhNkQNZnEZrH2VvR93W1XHD+WZmVmuIXNmIWkq8HVgBPDtiJhfcSQzazGfcVRnSBQLSSOA/wO8B+gG7pZ0fUQ8UG0yM9sWVXV/ubhsvSFRLIApwMqIeAxA0pXA8YCLhZlttcG83tMuhWeoFItxwBMN77uBP+m9kqSZwMz09nlJDxfc/2jg19uUsBx1zFXHTFDPXHXMBM61NXIz6YstSvJqZX6v9m7WOFSKhZq0xRYNEQuBhVu9c6krIjoHEqxMdcxVx0xQz1x1zATOtTXqmAmqyTVU7obqBvZqeD8eWFNRFjOztjNUisXdwCRJEyXtAEwHrq84k5lZ2xgS3VARsUnSx4CbyW6dvTgi7h/EQ2x111WL1DFXHTNBPXPVMRM419aoYyaoIJcituj6NzMze5Wh0g1lZmYVcrEwM7NcbV8sJE2V9LCklZLmVJThYknrJK1oaNtD0mJJj6Svu1eQay9Jt0l6UNL9ks6qOpukHSXdJemXKdM/VZ2pV74Rku6VdEMdcklaLWm5pGWSuuqQKWXYTdL3JT2U/n29vepckvZN36ee5TlJZ9cg18fTv/UVkhal/wMtz9TWxaJhGJH3AvsBMyTtV0GUS4CpvdrmALdGxCTg1vS+1TYBn4yItwCHAbPS96fKbBuBoyLiQGAyMFXSYRVnanQW8GDD+zrkOjIiJjfcl1+HTF8HfhQRfwwcSPY9qzRXRDycvk+TgUOAF4Frq8wlaRwwG+iMiAPIbvCZXkmmiGjbBXg7cHPD+7nA3IqydAArGt4/DIxNr8cCD9fg+3Ud2fhctcgG7AzcQ/Y0f+WZyJ7/uRU4CrihDn+PwGpgdK+2qjPtCqwi3WBTl1y9shwD/HvVuXhl9Io9yO5evSFla3mmtj6zoPkwIuMqytLbnhGxFiB9fUOVYSR1AAcBd1JxttTVswxYByyOiMozJV8D/h54uaGt6lwB3CJpaRoOpw6Z9gHWA/+auuy+LWmXGuRqNB1YlF5XlisingS+DPwKWAs8GxG3VJGp3YtFoWFE2p2k1wJXA2dHxHNV54mIzZF1FYwHpkg6oOJISHofsC4illadpZd3RMTBZF2tsyS9q+pAZL8hHwwsiIiDgBeorttwC+nB3/cD/7cGWXYnGzR1IvBGYBdJp1SRpd2LRZ2HEXlK0liA9HVdFSEkbU9WKC6PiGvqlC0ifgvcTna9p+pM7wDeL2k1cCVwlKTvVp0rItakr+vI+t+nVJ2J7P9ddzojBPg+WfGoOleP9wL3RMRT6X2Vud4NrIqI9RHxe+Aa4E+ryNTuxaLOw4hcD5yWXp9Gdr2gpSQJuAh4MCLOq0M2SWMk7ZZe70T2n+mhKjMBRMTciBgfER1k/47+LSJOqTKXpF0kjep5TdbXvaLKTAAR8f+BJyTtm5qOJptuoPJ/88kMXumCgmpz/Qo4TNLO6f/j0WQ3A7Q+U1UXkOqyAMcB/wE8CnymogyLyPojf0/2W9cZwOvJLpY+kr7uUUGuw8m65e4DlqXluCqzAW8D7k2ZVgCfS+2Vf78aMh7BKxe4q/xe7QP8Mi339/z7rsP3iuxOtq709/gDYPea5NoZ+A3wuoa2SnMB/0T2C9EK4DvAyCoyebgPMzPL1e7dUGZmVoCLhZmZ5XKxMDOzXC4WZmaWy8XCzMxyuVjYkCfp+RL2OVnScQ3vz5X0qW3Y3wfS6Kq3DU7CAedYLWl0lRlsaHKxMGtuMtkzJYPlDOBvI+LIQdynWcu4WNiwIunTku6WdF/DXBcd6bf6C9O8ALekp7+RdGhad4mkL6U5A3YAPg+cnOY1ODntfj9Jt0t6TNLsPo4/I80fsULSF1Pb58gecLxA0pd6rT9W0h3pOCskvTO1L5DUpYY5O1L7akn/K+XtknSwpJslPSrpo2mdI9I+r5X0gKQLJG3xf13SKcrmBlkm6VtpgMYRki5JWZZL+vg2/pXYcNHqJyS9eBnsBXg+fT2GbCJ7kf0idAPwLrLh3zcBk9N6VwGnpNcrgD9Nr+eThokHPgj8S8MxzgV+Tvb07Giyp3y375XjjWTDM4whGyzv34AT0me3k81J0Dv7J3nlyeoRwKj0eo+GttuBt6X3q4Ez0+uvkj0BPSodc11qPwJ4iewJ7hHAYuCvGrYfDbwF+H89fwbgm8CpZPM4LG7It1vVf79e6rH4zMKGk2PSci/ZPBd/DExKn62KiGXp9VKgI40xNSoifp7ar8jZ/40RsTEifk02cNuevT4/FLg9skHfNgGXkxWr/twNfEjSucBbI2JDaj9J0j3pz7I/2eRcPXrGL1sO3BkRGyJiPfBSz7hZwF0R8VhEbCYbTubwXsc9mqww3J2Gez+arLg8Buwj6RuSpgKVjzJs9fCaqgOYDSIB/xwR33pVYzYXx8aGps3ATjQfor4/vffR+//P1u6PiLgjDRs+DfhO6qb6KfAp4NCIeEbSJcCOTXK83CvTyw2Zeo/j0/u9gEsjYm7vTJIOBI4FZgEnAadv7Z/Lhh+fWdhwcjNwepp/A0njJPU5KUxEPANsUDYtK2SjxfbYQNa9szXuBP5M0mhlU/bOAH7S3waS9ibrPrqQbITfg8lmknsBeFbSnmRDZm+tKWk05e2Ak4Gf9fr8VuCver4/yuZ03jvdKbVdRFwN/GPKY+YzCxs+IuIWSW8BlmSjOfM8cArZWUBfzgAulPQC2bWBZ1P7bcCc1EXzzwWPv1bS3LStgJsiIm/o6COAT0v6fcp7akSsknQv2UixjwH/XuT4vSwhuwbzVuAOsrksGrM+IOmzZLPobUc24vEs4HdkM9j1/CK5xZmHtSePOmttTdJrI+L59HoO2bzGZ1Uca5tIOgL4VES8r+IoNoz4zMLa3bR0NvAa4HGyu6DMrBefWZiZWS5f4DYzs1wuFmZmlsvFwszMcrlYmJlZLhcLMzPL9V/tvmNZvuUJNgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('리뷰의 최대 길이 :',max(len(review) for review in X_train))\n",
    "print('리뷰의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n",
    "plt.hist([len(review) for review in X_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 샘플 중 길이가 max_len 이하인 샘플의 비율이 몇 %인지 확인하는 함수\n",
    "def below_threshold_len(max_len, nested_list):\n",
    "  count = 0\n",
    "  for sentence in nested_list:\n",
    "    if(len(sentence) <= max_len):\n",
    "        count = count + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (count / len(nested_list))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 30 이하인 샘플의 비율: 89.36926820138498\n"
     ]
    }
   ],
   "source": [
    "max_len = 30\n",
    "below_threshold_len(max_len, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체 샘플의 길이를 30으로 제한"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM을 통한 감성 분류\n",
    "\n",
    "최종 선정한 모델과의 정확도 비교를 위해 \n",
    "\n",
    "원문에서 사용했던 LSTM모델을 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "201/201 [==============================] - 12s 40ms/step - loss: 0.5073 - acc: 0.7502 - val_loss: 0.4546 - val_acc: 0.8041\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.80412, saving model to ./model_result\\LSTM_Best_Model.h5\n",
      "Epoch 2/15\n",
      "201/201 [==============================] - 8s 37ms/step - loss: 0.3708 - acc: 0.8360 - val_loss: 0.4424 - val_acc: 0.8026\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.80412\n",
      "Epoch 3/15\n",
      "201/201 [==============================] - 7s 37ms/step - loss: 0.3321 - acc: 0.8574 - val_loss: 0.4330 - val_acc: 0.8088\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.80412 to 0.80880, saving model to ./model_result\\LSTM_Best_Model.h5\n",
      "Epoch 4/15\n",
      "201/201 [==============================] - 8s 37ms/step - loss: 0.3044 - acc: 0.8723 - val_loss: 0.4344 - val_acc: 0.8016\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.80880\n",
      "Epoch 5/15\n",
      "201/201 [==============================] - 7s 37ms/step - loss: 0.2812 - acc: 0.8854 - val_loss: 0.4297 - val_acc: 0.8075\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.80880\n",
      "Epoch 6/15\n",
      "201/201 [==============================] - 7s 36ms/step - loss: 0.2598 - acc: 0.8918 - val_loss: 0.4474 - val_acc: 0.8010\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.80880\n",
      "Epoch 7/15\n",
      "201/201 [==============================] - 7s 36ms/step - loss: 0.2396 - acc: 0.9024 - val_loss: 0.4703 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.80880\n",
      "Epoch 8/15\n",
      "201/201 [==============================] - 7s 36ms/step - loss: 0.2183 - acc: 0.9148 - val_loss: 0.4990 - val_acc: 0.7969\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.80880\n",
      "Epoch 9/15\n",
      "201/201 [==============================] - 7s 36ms/step - loss: 0.1992 - acc: 0.9219 - val_loss: 0.5432 - val_acc: 0.7969\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.80880\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "embedding_dim = 100\n",
    "hidden_units = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(LSTM(hidden_units))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('./model_result/LSTM_Best_Model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step - loss: 0.4135 - acc: 0.8092\n",
      "\n",
      " 테스트 정확도: 0.8092\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model('./model_result/LSTM_Best_Model.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 리뷰 예측해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_predict(new_sentence):\n",
    "  new_sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','', new_sentence)\n",
    "  new_sentence = kkma.morphs(new_sentence) # 토큰화\n",
    "  new_sentence = [word for word in new_sentence if not word in stopwords] # 불용어 제거\n",
    "  encoded = tokenizer.texts_to_sequences([new_sentence]) # 정수 인코딩\n",
    "  pad_new = pad_sequences(encoded, maxlen = max_len) # 패딩\n",
    "  score = float(loaded_model.predict(pad_new)) # 예측\n",
    "  if(score > 0.5):\n",
    "    print(\"{:.2f}% 확률로 긍정 리뷰입니다.\\n\".format(score * 100))\n",
    "  else:\n",
    "    print(\"{:.2f}% 확률로 부정 리뷰입니다.\\n\".format((1 - score) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.86% 확률로 긍정 리뷰입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_predict('이 영화 개꿀잼 ㅋㅋㅋ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiLSTM으로 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "51/51 [==============================] - 14s 164ms/step - loss: 0.5510 - acc: 0.7160 - val_loss: 0.5544 - val_acc: 0.7480\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.74797, saving model to ./model_result\\BiLSTM_Best_Model.h5\n",
      "Epoch 2/15\n",
      "51/51 [==============================] - 7s 140ms/step - loss: 0.3937 - acc: 0.8288 - val_loss: 0.4528 - val_acc: 0.8060\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.74797 to 0.80599, saving model to ./model_result\\BiLSTM_Best_Model.h5\n",
      "Epoch 3/15\n",
      "51/51 [==============================] - 7s 134ms/step - loss: 0.3330 - acc: 0.8610 - val_loss: 0.8105 - val_acc: 0.6984\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.80599\n",
      "Epoch 4/15\n",
      "51/51 [==============================] - 7s 133ms/step - loss: 0.3133 - acc: 0.8712 - val_loss: 0.5209 - val_acc: 0.7402\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.80599\n",
      "Epoch 5/15\n",
      "51/51 [==============================] - 7s 130ms/step - loss: 0.2838 - acc: 0.8858 - val_loss: 0.5487 - val_acc: 0.7957\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.80599\n",
      "Epoch 6/15\n",
      "51/51 [==============================] - 7s 129ms/step - loss: 0.2621 - acc: 0.8960 - val_loss: 0.5265 - val_acc: 0.7845\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.80599\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM, Bidirectional\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "embedding_dim = 100\n",
    "hidden_units = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(Bidirectional(LSTM(hidden_units))) # Bidirectional LSTM을 사용\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('./model_result/BiLSTM_Best_Model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=256, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 11ms/step - loss: 0.4302 - acc: 0.8053\n",
      "테스트 정확도: 0.8053\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model('./model_result/BiLSTM_Best_Model.h5')\n",
    "print(\"테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.23% 확률로 긍정 리뷰입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_predict('조금 어렵지만 재밌음ㅋㅋ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **0319 작업 기록 메모**\n",
    "데이터를 원본 그대로 쓰지 않고 줄여놨더니 문제 발생\n",
    "\n",
    "원인 : x와 y의 사이즈가 맞지 않음\n",
    "\n",
    "추측 : LSTM이 다대일인데 X가 Y보다 적어서 발생한 것으로 추정\n",
    "\n",
    "팀 회의에선 3만개로 줄이기로 제안했지만\n",
    "\n",
    "5만개로 변경해보고 진행\n",
    "\n",
    "이래도 안될 경우 데스크탑에서 원본 그대로 해보기로 진행"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7943164eb5f574a26040379735458990a5da9074c282f374d9295ab10da3c06"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
